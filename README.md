# ğŸ“Š OpsIntel360 - Business Operations Insights Dashboard

> A comprehensive, production-ready data analytics and forecasting platform providing actionable insights across Finance, Sales, Operations, HR, and IT departments.

![Python](https://img.shields.io/badge/Python-3.11-blue)
![Streamlit](https://img.shields.io/badge/Streamlit-1.30-red)
![Prophet](https://img.shields.io/badge/Prophet-1.1-green)
![License](https://img.shields.io/badge/License-MIT-yellow)

## ğŸ¯ Project Overview

OpsIntel360 is a full-stack data analytics platform that combines:
- **Time-series forecasting** using Facebook Prophet
- **Anomaly detection** with Isolation Forest and Z-Score methods
- **Interactive visualizations** with Plotly
- **AI-generated insights** and recommendations
- **Real-time dashboards** built with Streamlit

Perfect for showcasing data analytics and machine learning engineering capabilities in a portfolio.

## âœ¨ Key Features

### ğŸ“ˆ Multi-Domain Analytics
- **Finance**: Revenue, expenses, profit margins, budget variance
- **Sales**: Regional performance, conversion rates, deal sizes
- **Operations**: Order processing, on-time delivery, efficiency metrics
- **HR**: Employee count, turnover rates, satisfaction scores
- **IT Support**: Ticket volumes, resolution times, priority analysis

### ğŸ”® Advanced Forecasting
- Facebook Prophet time-series forecasting
- Configurable forecast horizons (3-12 months)
- Confidence intervals and accuracy metrics (RMSE, MAE, MAPE)
- Interactive forecast visualization

### âš ï¸ Intelligent Anomaly Detection
- Dual detection methods: Z-Score and Isolation Forest
- Automatic outlier identification
- Contextual anomaly explanations
- Historical comparison visualizations

### ğŸ’¡ AI-Powered Insights
- Rule-based recommendation engine
- Severity classification (Critical, Warning, Info)
- Category-specific insights
- Exportable reports (JSON)

### ğŸ¨ Modern Dashboard
- Clean, professional UI with custom CSS
- Interactive Plotly charts
- Real-time KPI cards
- Multi-tab navigation
- Responsive design

## ğŸ—ï¸ Project Structure

```
opsintel360/
â”œâ”€â”€ data/                          # Generated CSV datasets
â”‚   â”œâ”€â”€ finance.csv
â”‚   â”œâ”€â”€ sales.csv
â”‚   â”œâ”€â”€ operations.csv
â”‚   â”œâ”€â”€ hr.csv
â”‚   â””â”€â”€ it_tickets.csv
â”œâ”€â”€ database/                      # SQLite database
â”‚   â”œâ”€â”€ schema.sql
â”‚   â””â”€â”€ opsintel.db
â”œâ”€â”€ etl/                          # ETL pipeline
â”‚   â”œâ”€â”€ etl_pipeline.py           # Main ETL orchestration
â”‚   â””â”€â”€ utils.py                  # Database utilities
â”œâ”€â”€ models/                       # ML models
â”‚   â”œâ”€â”€ forecasting.py            # Prophet forecasting
â”‚   â”œâ”€â”€ anomalies.py              # Anomaly detection
â”‚   â””â”€â”€ insights.py               # Insight generation
â”œâ”€â”€ app/                          # Streamlit application
â”‚   â””â”€â”€ dashboard_app.py          # Main dashboard
â”œâ”€â”€ config.py                     # Configuration settings
â”œâ”€â”€ generate_data.py              # Synthetic data generation
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ Dockerfile                    # Container definition
â”œâ”€â”€ docker-compose.yml            # Service orchestration
â””â”€â”€ README.md                     # Documentation
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11+
- pip or conda
- Docker (optional, for containerized deployment)

### Installation

#### Option 1: Local Installation

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/opsintel360.git
cd opsintel360
```

2. **Create virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Generate synthetic data and initialize database**
```bash
python generate_data.py
python etl/etl_pipeline.py
```

5. **Run the dashboard**
```bash
streamlit run app/dashboard_app.py
```

6. **Open browser** to `http://localhost:8501`

#### Option 2: Docker Deployment

1. **Build and run with Docker Compose**
```bash
docker-compose up --build
```

2. **Access dashboard** at `http://localhost:8501`

## ğŸ“Š Usage Guide

### Running the ETL Pipeline

The ETL pipeline loads data from CSV files into SQLite:

```bash
# Run with default settings
python etl/etl_pipeline.py

# Regenerate data before loading
python etl/etl_pipeline.py --regenerate
```

### Generating Forecasts

Run forecasting separately for all key metrics:

```bash
python models/forecasting.py
```

### Detecting Anomalies

Execute anomaly detection across all metrics:

```bash
python models/anomalies.py
```

### Generating Insights

Generate AI-powered business recommendations:

```bash
python models/insights.py
```

## ğŸ¨ Dashboard Features

### KPI Overview Tab
- **Real-time metrics**: Revenue, Profit, Margins, Delivery Performance
- **Trend visualizations**: Financial performance over time
- **Regional analysis**: Sales breakdown by geography
- **MoM comparisons**: Month-over-month growth indicators

### Forecasting Tab
- **Interactive predictions**: Select metrics and forecast horizons
- **Model accuracy**: RMSE, MAE, and MAPE metrics
- **Confidence intervals**: Upper and lower bound visualizations
- **Forecast tables**: Detailed numerical predictions

### Anomalies Tab
- **Automated detection**: Identifies unusual patterns
- **Visual highlighting**: Anomalies marked on time-series charts
- **Detailed analysis**: Z-scores and anomaly scores
- **Contextual insights**: Explanations for detected outliers

### Recommendations Tab
- **Severity filtering**: Critical, Warning, Info classifications
- **Category filtering**: Finance, Sales, Operations, HR, IT
- **Actionable insights**: Specific, data-driven recommendations
- **Export functionality**: Download insights as JSON

## ğŸ”§ Configuration

### Database Settings
Edit `config.py` to customize:
- Data generation parameters (start date, periods, frequency)
- Forecast configuration (horizon, seasonality, priors)
- Anomaly detection thresholds
- KPI targets and thresholds

### Environment Variables
Copy `.env.example` to `.env` and configure:
```bash
cp .env.example .env
```

## ğŸ“ˆ Data Generation

The platform includes a sophisticated synthetic data generator:

```python
from generate_data import generate_all_data

# Generate 24 months of synthetic business data
finance_df, sales_df, operations_df, hr_df, it_tickets_df = generate_all_data()
```

**Data Characteristics:**
- Realistic trends and seasonality
- Region-specific patterns
- Correlated metrics (e.g., revenue drives expenses)
- Time-series improvements (e.g., efficiency gains)
- Random noise for authenticity

## ğŸ§ª Testing

### Run Manual Tests
```bash
# Test data generation
python generate_data.py

# Test ETL pipeline
python etl/etl_pipeline.py

# Test forecasting
python models/forecasting.py

# Test anomaly detection
python models/anomalies.py

# Test insights generation
python models/insights.py
```

## ğŸ“¦ Deployment

### Deploy to Streamlit Cloud

1. Push code to GitHub
2. Visit [Streamlit Cloud](https://streamlit.io/cloud)
3. Connect repository
4. Deploy with `app/dashboard_app.py` as entry point

### Deploy to Heroku

1. Create `Procfile`:
```
web: streamlit run app/dashboard_app.py --server.port=$PORT
```

2. Deploy:
```bash
heroku create opsintel360
git push heroku main
```

### Deploy with Docker

```bash
# Build image
docker build -t opsintel360 .

# Run container
docker run -p 8501:8501 opsintel360
```

## ğŸ› ï¸ Technology Stack

| Category | Technologies |
|----------|-------------|
| **Languages** | Python 3.11 |
| **Data Processing** | Pandas, NumPy, SQLAlchemy |
| **Machine Learning** | Prophet, Scikit-learn |
| **Visualization** | Plotly, Matplotlib, Seaborn |
| **Web Framework** | Streamlit |
| **Database** | SQLite |
| **Deployment** | Docker, Docker Compose |

## ğŸ“š Key Dependencies

- **Prophet 1.1**: Time-series forecasting
- **Streamlit 1.30**: Interactive web applications
- **Plotly 5.18**: Interactive visualizations
- **Scikit-learn 1.4**: Anomaly detection (Isolation Forest)
- **Pandas 2.1**: Data manipulation
- **SQLAlchemy 2.0**: Database ORM

## ğŸ“ Learning Outcomes

This project demonstrates proficiency in:
- âœ… Full-stack data engineering
- âœ… Time-series forecasting with Prophet
- âœ… Anomaly detection algorithms
- âœ… ETL pipeline design
- âœ… Database schema design
- âœ… Interactive dashboard development
- âœ… Python best practices and code organization
- âœ… Docker containerization
- âœ… Data visualization techniques
- âœ… Business intelligence and KPI tracking

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ‘¤ Author

**David Madison**
- Graduate Student in Data Analytics
- Research Assistant in AI & Robotics
- [LinkedIn](https://www.linkedin.com/in/davidmadison95/) | [GitHub](https://github.com/davidmadison95)

## ğŸ™ Acknowledgments

- Built with Python, Streamlit, Prophet, and other open-source technologies.

## ğŸ“§ Contact

For questions or feedback, please open an issue or contact:
- Email: davidmadison95@yahoo.com
- LinkedIn: [https://www.linkedin.com/in/davidmadison95/]

---

**â­ If you find this project useful, please consider giving it a star on GitHub!**

Built with â¤ï¸ using Python, Streamlit, and Prophet
